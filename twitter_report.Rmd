---
title: "Report on Twitter"
output:
  html_document:
    theme: united
    toc: yes
  pdf_document:
    toc: yes
  word_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning=FALSE)
```

# Approach 
In this report, I extracted data from https://twitter.com/Unilever via Twitter API to answer some of my questions on this communication channel of Unilever:
- General performance
- What kinds of posts appeal most to Internet users?
- What are people talking about Unilever on the Internet?
- Who are among the influencial users?
- Sentiment analysis

# Improvement 
- Although I got this twitter from the offical website of Unilever, twitter or facebook can only be a minor PR channel of the company. Therefore, the conclusion in this report might be incomprehensive, and we need more internal data to verify. 
- There are many other factors that haven't been counted in this report, such as marketing campaign. If I have more time working on this. I will cover competitors' social data as well.


```{r setting, include=FALSE}
### Call lib 
### --------------------------------------------------------------
library(ROAuth)
library(twitteR)
library(tm)
library(RColorBrewer)
library(wordcloud)
library(lubridate)
library(dplyr)
library(DT)
library(tidytext)
library(tidyr)
library(ggplot2)


### Authentication
### --------------------------------------------------------------
api_key <- "gqZ3F136CxDOugyhnj9DDQUrU"
api_secret <- "jf4Urqwwl9gMAsAeeoOnVevKXCFcoZoE5jjAb535CFXUrPVvKi"
access_token <- "795819471298392065-Va0xZTIbwLSXVazEHy1aOYyPHcKr3PI"
access_token_secret <- "jtejpDdSOg9t7W5KSYwfPXeitlfWLCUUIVg83yWXzPMGS"

setup_twitter_oauth(api_key,api_secret)


### Setting 
### --------------------------------------------------------------
setwd("/Users/mainguyen/Analytics/social_listening")

```


# Social Analysis 

## General performance of Twitter

* In this section, I get data from Uniliever timeline since the beginning of 2017.

```{r get-timeline, echo=TRUE}
# Get timeline tweets
# tweets <- userTimeline("Unilever", n = 3200)
# save(tweets, file="tweets.Rdata")
load("tweets.Rdata")
# tweets.df <- twListToDF(tweets)
# save(tweets.df, file="tweets.df.Rdata")
load("tweets.df.Rdata")
```

```{r timeline-clean, include=FALSE}
# Remove replies 
tweets.df <- tweets.df[is.na(tweets.df$replyToSN),]

# Clean date
tweets.df$date_created <- as.Date(tweets.df$created)
tweets.df$hour <- hour(tweets.df$created)

```

* Top tweets

This table shows the top 10 tweet that have the most number of favorite and retweet counts. One common characteristic among these tweets is that they all express concern on social issues, showing Unilever is a caring brand. 

```{r top-twt, results='asis'}
# List of top 10% tweet
top_tweet <- arrange(tweets.df, desc(favoriteCount)) %>%
  select(text, date_created, favoriteCount, retweetCount) %>%
  head(n=10) %>%
  datatable()
top_tweet
```

* Time of the day with most tweets and most favorite

Time is one of the most important factor in determining the effectiveness of public communication as we don't want to engage users when they are working "very hard" or sleeping. Most common timeframe to tweet is from 10am - 2pm (People might spend sometime browsing the Internet during breakfast or lunch, so this makes sense). I added 'average favorite per tweet' to see where each tweet in this timeframe attracts users. And they do. This metrics is not perfect but it is able to show the outstanding trend. 

```{r top-time, results='asis'}
top_time <- tweets.df %>%
  filter(favoriteCount<1000) %>%
  group_by(hour) %>%
  summarise(number_of_tweets=length(unique(id)),
            number_of_favorite=sum(favoriteCount),
            number_of_retweet=sum(retweetCount)) %>%
  mutate(avg_favorite=round(number_of_favorite/number_of_tweets, digit=0),
         avg_retweet=round(number_of_retweet/number_of_tweets, digit=0))

top_time <- filter(top_time, top_time$number_of_tweets > 1)

top_time <- datatable(top_time)
top_time
  
```

## What are people talking about Unilever

* In this section, I retrieve tweets that mention the word "Unilever". Since the amount of data in this case is huge, I initially extracted data from July 18th until now. 

```{r mention-tweet, echo=TRUE}
# Get tweets mentioning Unilever
# search_tweet <- searchTwitter("Unilever", n=20000)
# save(search_tweet, file="search_tweet.Rdata")
load("search_tweet.Rdata")
# search.tweet.df <- twListToDF(search_tweet)
# save(search.tweet.df, file="search.tweet.df.Rdata")
load("search.tweet.df.Rdata")
```

```{r mention-clean, include=FALSE}
# Remove replies 
search.tweet.df <- search.tweet.df[is.na(search.tweet.df$replyToSN),]

# Clean date
search.tweet.df$date_created <- as.Date(search.tweet.df$created)
search.tweet.df$hour <- hour(search.tweet.df$created)
```

### Top people who tweet about Unilever

* I want to see who are the most influencial Twitter users whose tweets appeal alot of attention from other users. I use the average favorite per tweet in this case. Please note that I don't take into account tweets from Paul Polman and Unilerver itself, obviously. 

```{r most-influ, results='asis', echo=FALSE}
tweet_people <- search.tweet.df %>%
  group_by(screenName) %>%
  summarise(number_of_tweets=length(unique(id)),
            number_of_favorite=sum(favoriteCount),
            number_of_retweet=sum(retweetCount)) %>%
  mutate(avg_favorite=round(number_of_favorite/number_of_tweets, digit=0),
         avg_retweet=round(number_of_retweet/number_of_tweets, digit=0)) 
  
top_people <- tweet_people %>%
  filter(number_of_tweets > 1) %>%
  filter(!screenName %in% c("PaulPolman", "Unilever")) %>%
  arrange(desc(avg_favorite)) %>%
  head(n=10) %>%
  datatable()
top_people
```

* On the other hand, I also see those users who tweet alot about Unilever. I remove the users that post a lot of stock updates, because they are out of this scope and also mislead the data. If I have more time, I will go mine more about this tweet data to see what are their concern. 

```{r most-twt, results='asis', echo=FALSE}
most_tweet_people <- tweet_people %>%
  filter(!screenName %in% c("doshi_rahul", "Unilever_Canada")) %>%
  arrange(desc(number_of_tweets)) %>%
  head(n=10) %>%
  datatable()
most_tweet_people
```

### Top words people use as they mention Unilever

* Most frenquently mentioned words apparently contain Pepsico and other brands such as Nestle, Procter&Gamble, as some of the biggest compititors in F&B industry. 
* However, the most outstansing words in this case question us on environment issues related to Unilever. The presence of 'Nestle', 'Pepsico', 'rainforest', 'destruction', 'elephants' however, gives us a hint that people are having concern what these companies are doing with deforestation. I did some search and found some articles talking about Pepsico, Unilever and Nestlé being accused of complicity in illegal rainforest destruction, which leads to the "destruction of the last place on earth where Sumatran elephants, orangutans, rhinos and tigers". 

```{r word-cloud, results='asis', echo=FALSE}
search.tweet.text <- sapply(search_tweet, function(x) x$getText())
search.tweet.text <- sapply(search.tweet.text, function(row) iconv(row, "latin1", "ASCII", sub=""))

# Remove punctuation
search.tweet.text <- gsub("[[:punct:]]", "", search.tweet.text)
# Convert all text to lower case
search.tweet.text <- tolower(search.tweet.text)
# Replace blank space (“rt”)
search.tweet.text <- gsub("rt", "", search.tweet.text)
# Replace @UserName
search.tweet.text <- gsub("@\\w+", "", search.tweet.text)
# Remove links
search.tweet.text <- gsub("http\\w+", "", search.tweet.text)
# Remove tabs
search.tweet.text <- gsub("[ |\t]{2,}", "", search.tweet.text)
# Remove blank spaces at the beginning
search.tweet.text <- gsub("^ ", "", search.tweet.text)
# Remove blank spaces at the end
search.tweet.text <- gsub(" $", "", search.tweet.text)
# Create corpus
tweets.text.corpus <- Corpus(VectorSource(search.tweet.text))
# Clean up by removing stop words
tweets.text.corpus <- tm_map(tweets.text.corpus, function(x) removeWords(x,stopwords()))

wc <- wordcloud(tweets.text.corpus, min.freq = 2, scale=c(7,0.5),colors=brewer.pal(8, "Dark2"),  random.color= TRUE, random.order = FALSE, max.words = 150)
wc
```

* More specifically, here is the frequency at which the words are mentioned around Unilever. This finding confirms the argument above as the words related to environment issues obviouly outnumber the others. 

```{r freq, results='asis', echo=FALSE}
tdm <- TermDocumentMatrix(tweets.text.corpus,
                      control = list(wordLengths = c(1, Inf)))
term.freq <- rowSums(as.matrix(tdm))
term.freq <- subset(term.freq, term.freq >= 15)
df <- data.frame(term = names(term.freq), freq = term.freq)
top_freq <- df %>%
  arrange(desc(freq)) %>%
  head(n=20) %>%
  datatable()
top_freq
```

### Sentiment Analysis

* There are namely 3 ways in determining whether a word is negative or positive. ("nrc" - lexicon categorizes words of positive, negative, anger, anticipation, disgust, fear, joy, sadness, surprise, and trust. "bing"" lexicon categorizes words in a binary fashion into positive and negative categories. "AFINN" lexicon give a word a score from -5 to 5 (negative to positive). For this purpose I use "Bing". 

* This chart shows the different between the frequency of positive words and negative words. As it goes below 0, it shows more negative words are being used around "Unilever".

```{r plot-1, results='asis', echo=FALSE}
search.sent <- search.tweet.df %>%
  select(text, date_created) %>%
  unnest_tokens(word, text) %>%
  inner_join(get_sentiments("bing"), by="word") %>%
  count(date_created, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>%
  mutate(pos=ifelse(sentiment>=0, "TRUE", "FALSE"))

#plot
sent_plot <- ggplot(search.sent, aes(x=date_created, y=sentiment, fill=pos)) +
  geom_bar(stat="identity") +
  #geom_text(aes(label=date_created), vjust=0.2, colour="black", size=2) +
  theme_minimal() +
  labs(y = "Minus means negative more than positive", x = "Date") +
  theme(axis.title.y = element_text(size = 7)) +
  theme(axis.title.x = element_text(size = 7)) +
  theme(axis.text.x = element_text(angle = 75, hjust=1, face = "italic", size = 7)) +
  theme(axis.text.y = element_text(size = 7)) +
  guides(fill=FALSE) +
  #theme(legend.text=element_blank()) +
  #theme(legend.key=element_blank()) +
  theme(panel.grid.minor.x = element_blank(),
        panel.grid.major.x = element_blank(),
        panel.grid.minor.y = element_blank(),
        panel.grid.major.y = element_line(color = "gray90")) 
  #scale_fill_manual("lightcoral") 
  #scale_y_continuous(breaks = seq(0, 50, by=5))
print(sent_plot)

```

* Most common positive and negative words can be seen in this chart. It shows that people truly concern on enviromental practices that large FMCG corporates are implementing. People also talk about sustainability as a positive side. 

```{r plot-2, results='asis', echo=FALSE}
top_word <- search.tweet.df %>%
  select(text) %>%
  unnest_tokens(word, text) %>%
  inner_join(get_sentiments("bing"), by="word") %>%
  count(word, sentiment) 
  #filter(sentiment == "positive") %>%
  #arrange(desc(n)) %>%
  #head(n=15) %>%
  #datatable()

top_word %>%
  group_by(sentiment) %>%
  top_n(15) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  guides(fill=guide_legend(title = NULL)) +
  facet_wrap(~sentiment, scales = "free_y") +
  theme(axis.title.x = element_blank()) +
  theme(axis.title.y = element_blank()) +
  theme(axis.text.x = element_text(size = 8)) +
  theme(axis.text.y = element_text(size = 8)) +
  theme(axis.ticks = element_blank()) +
  coord_flip()

top_word
```

* Data of the last 10 days show that people are talking about more negative things when it comes to Unilever, due to the rumor on illegal destruction. What needs to be done would be a stated commitment on environmental protection and sustainable manufacturing from Unilever and a join force from other companies in the industry. s